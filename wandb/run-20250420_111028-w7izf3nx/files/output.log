INFO:drake:Meshcat listening for connections at http://localhost:7000
WARNING:drake:warning: Warning: In vtkGLTFDocumentLoaderInternals.cxx, line 1354: vtkGLTFDocumentLoader (0x5fe203aa29c0): glTF extension KHR_texture_basisu is used in this model, but not supported by this loader. The extension will be ignored.
/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/env_checker.py:462: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf. https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html
  warnings.warn(
/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/env_checker.py:473: UserWarning: Your action space has dtype float64, we recommend using np.float32 to avoid cast errors.
  warnings.warn(
Creating PPO model...
Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Total number of parameters: 392975
Logging to runs/0419/PPO_25
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2        |
|    ep_rew_mean     | 1.52     |
| time/              |          |
|    fps             | 145      |
|    iterations      | 1        |
|    time_elapsed    | 14       |
|    total_timesteps | 2048     |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2           |
|    ep_rew_mean          | 1.52        |
| time/                   |             |
|    fps                  | 161         |
|    iterations           | 2           |
|    time_elapsed         | 25          |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.009673569 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | 0.00636     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0872      |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0043     |
|    std                  | 1.01        |
|    value_loss           | 2.52        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2           |
|    ep_rew_mean          | 1.52        |
| time/                   |             |
|    fps                  | 168         |
|    iterations           | 3           |
|    time_elapsed         | 36          |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.008090267 |
|    clip_fraction        | 0.0207      |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.98       |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.0003      |
|    loss                 | -0.001      |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.00102    |
|    std                  | 1.01        |
|    value_loss           | 12.5        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2           |
|    ep_rew_mean          | 1.52        |
| time/                   |             |
|    fps                  | 173         |
|    iterations           | 4           |
|    time_elapsed         | 47          |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.014448755 |
|    clip_fraction        | 0.0901      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0154      |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00465    |
|    std                  | 1.01        |
|    value_loss           | 8.75        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2           |
|    ep_rew_mean          | 1.52        |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 5           |
|    time_elapsed         | 58          |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.018847762 |
|    clip_fraction        | 0.0998      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0145     |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00204    |
|    std                  | 1.01        |
|    value_loss           | 5.32        |
-----------------------------------------
Finish!
Logging to runs/0419/PPO_25
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2        |
|    ep_rew_mean     | 1.52     |
| time/              |          |
|    fps             | 214      |
|    iterations      | 1        |
|    time_elapsed    | 9        |
|    total_timesteps | 12288    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2           |
|    ep_rew_mean          | 1.52        |
| time/                   |             |
|    fps                  | 196         |
|    iterations           | 2           |
|    time_elapsed         | 20          |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.009335636 |
|    clip_fraction        | 0.0589      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0265      |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00015    |
|    std                  | 1.02        |
|    value_loss           | 1.8         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2           |
|    ep_rew_mean          | 1.52        |
| time/                   |             |
|    fps                  | 192         |
|    iterations           | 3           |
|    time_elapsed         | 31          |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.008305626 |
|    clip_fraction        | 0.089       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00994     |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.00159    |
|    std                  | 1.04        |
|    value_loss           | 1.04        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2           |
|    ep_rew_mean          | 1.52        |
| time/                   |             |
|    fps                  | 191         |
|    iterations           | 4           |
|    time_elapsed         | 42          |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.013667885 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0211     |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.00295    |
|    std                  | 1.05        |
|    value_loss           | 0.587       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2            |
|    ep_rew_mean          | 1.52         |
| time/                   |              |
|    fps                  | 190          |
|    iterations           | 5            |
|    time_elapsed         | 53           |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 0.0061452314 |
|    clip_fraction        | 0.105        |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.3        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00802     |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00186     |
|    std                  | 1.06         |
|    value_loss           | 0.342        |
------------------------------------------
Finish!
Logging to runs/0419/PPO_25
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2        |
|    ep_rew_mean     | 1.52     |
| time/              |          |
|    fps             | 208      |
|    iterations      | 1        |
|    time_elapsed    | 9        |
|    total_timesteps | 22528    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2           |
|    ep_rew_mean          | 1.52        |
| time/                   |             |
|    fps                  | 198         |
|    iterations           | 2           |
|    time_elapsed         | 20          |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.013124782 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00585    |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0031     |
|    std                  | 1.08        |
|    value_loss           | 0.115       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2          |
|    ep_rew_mean          | 1.52       |
| time/                   |            |
|    fps                  | 194        |
|    iterations           | 3          |
|    time_elapsed         | 31         |
|    total_timesteps      | 26624      |
| train/                  |            |
|    approx_kl            | 0.00928606 |
|    clip_fraction        | 0.14       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 1.19e-07   |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0188    |
|    n_updates            | 120        |
|    policy_gradient_loss | -0.00262   |
|    std                  | 1.09       |
|    value_loss           | 0.0691     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2           |
|    ep_rew_mean          | 1.52        |
| time/                   |             |
|    fps                  | 194         |
|    iterations           | 4           |
|    time_elapsed         | 42          |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.015623355 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0239      |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.00467    |
|    std                  | 1.1         |
|    value_loss           | 0.0401      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2          |
|    ep_rew_mean          | 1.52       |
| time/                   |            |
|    fps                  | 193        |
|    iterations           | 5          |
|    time_elapsed         | 52         |
|    total_timesteps      | 30720      |
| train/                  |            |
|    approx_kl            | 0.01712298 |
|    clip_fraction        | 0.145      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00561    |
|    n_updates            | 140        |
|    policy_gradient_loss | -0.00431   |
|    std                  | 1.11       |
|    value_loss           | 0.0246     |
----------------------------------------
Finish!
Logging to runs/0419/PPO_25
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2        |
|    ep_rew_mean     | 1.52     |
| time/              |          |
|    fps             | 207      |
|    iterations      | 1        |
|    time_elapsed    | 9        |
|    total_timesteps | 32768    |
---------------------------------
Traceback (most recent call last):
  File "/home/yyan-admin/yl43338/residual_grasping/train.py", line 138, in <module>
    sys.exit(main())
  File "/home/yyan-admin/yl43338/residual_grasping/train.py", line 125, in main
    model.learn(
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn
    return super().learn(
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 324, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 218, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 222, in step
    return self.step_wait()
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 59, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/gymnasium/wrappers/common.py", line 393, in step
    return super().step(action)
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/gymnasium/core.py", line 327, in step
    return self.env.step(action)
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/gymnasium/wrappers/common.py", line 285, in step
    return self.env.step(action)
  File "/home/yyan-admin/yl43338/residual_grasping/envs/one_step_end2end_grasp.py", line 435, in step
    observation = self.observation_port.Eval(context)
  File "/home/yyan-admin/yl43338/residual_grasping/envs/one_step_end2end_grasp.py", line 291, in CalcObs
    cloud = self.get_input_port(0).Eval(context)
  File "/home/yyan-admin/yl43338/residual_grasping/envs/one_step_end2end_grasp.py", line 86, in CalcOutput
    cloud = self.get_input_port(i).Eval(context)
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/manipulation/systems.py", line 45, in _CalcOutput
    def _CalcOutput(self, context, output):
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yyan-admin/yl43338/residual_grasping/train.py", line 138, in <module>
    sys.exit(main())
  File "/home/yyan-admin/yl43338/residual_grasping/train.py", line 125, in main
    model.learn(
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn
    return super().learn(
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 324, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 218, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 222, in step
    return self.step_wait()
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 59, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/gymnasium/wrappers/common.py", line 393, in step
    return super().step(action)
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/gymnasium/core.py", line 327, in step
    return self.env.step(action)
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/gymnasium/wrappers/common.py", line 285, in step
    return self.env.step(action)
  File "/home/yyan-admin/yl43338/residual_grasping/envs/one_step_end2end_grasp.py", line 435, in step
    observation = self.observation_port.Eval(context)
  File "/home/yyan-admin/yl43338/residual_grasping/envs/one_step_end2end_grasp.py", line 291, in CalcObs
    cloud = self.get_input_port(0).Eval(context)
  File "/home/yyan-admin/yl43338/residual_grasping/envs/one_step_end2end_grasp.py", line 86, in CalcOutput
    cloud = self.get_input_port(i).Eval(context)
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/manipulation/systems.py", line 45, in _CalcOutput
    def _CalcOutput(self, context, output):
KeyboardInterrupt
