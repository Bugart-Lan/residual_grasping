diff --git a/__pycache__/GraspPlanner.cpython-310.pyc b/__pycache__/GraspPlanner.cpython-310.pyc
index 880c059..62a915a 100644
Binary files a/__pycache__/GraspPlanner.cpython-310.pyc and b/__pycache__/GraspPlanner.cpython-310.pyc differ
diff --git a/__pycache__/GraspSelector.cpython-310.pyc b/__pycache__/GraspSelector.cpython-310.pyc
index 14d9e43..6ae7725 100644
Binary files a/__pycache__/GraspSelector.cpython-310.pyc and b/__pycache__/GraspSelector.cpython-310.pyc differ
diff --git a/__pycache__/utils.cpython-310.pyc b/__pycache__/utils.cpython-310.pyc
index 1354541..18069e7 100644
Binary files a/__pycache__/utils.cpython-310.pyc and b/__pycache__/utils.cpython-310.pyc differ
diff --git a/envs/residual_one.py b/envs/residual_one.py
index 9d5e743..b7c9eeb 100644
--- a/envs/residual_one.py
+++ b/envs/residual_one.py
@@ -113,7 +113,7 @@ far = 10.0
 renderer = "my_renderer"
 image_size = width * height * 4
 CAMERA_INSTANCE_PREFIX = "camera"
-cloud_size = 150
+cloud_size = 400
 
 # Gym parameters
 sim_time_step = 0.001
diff --git a/images/ResidualGraspOne-v0-diagram.png b/images/ResidualGraspOne-v0-diagram.png
index 23c842b..05d2950 100644
Binary files a/images/ResidualGraspOne-v0-diagram.png and b/images/ResidualGraspOne-v0-diagram.png differ
diff --git a/runs/0420/PPO_13/events.out.tfevents.1745168528.mech-d23074.austin.utexas.edu.2236535.0 b/runs/0420/PPO_13/events.out.tfevents.1745168528.mech-d23074.austin.utexas.edu.2236535.0
index c8f7cf1..45490c5 100644
Binary files a/runs/0420/PPO_13/events.out.tfevents.1745168528.mech-d23074.austin.utexas.edu.2236535.0 and b/runs/0420/PPO_13/events.out.tfevents.1745168528.mech-d23074.austin.utexas.edu.2236535.0 differ
diff --git a/wandb/debug-internal.log b/wandb/debug-internal.log
index 585a391..3b5c886 120000
--- a/wandb/debug-internal.log
+++ b/wandb/debug-internal.log
@@ -1 +1 @@
-run-20250420_120201-8jipcypo/logs/debug-internal.log
\ No newline at end of file
+run-20250420_164737-uuz1f1ij/logs/debug-internal.log
\ No newline at end of file
diff --git a/wandb/debug.log b/wandb/debug.log
index b49a224..9df527c 120000
--- a/wandb/debug.log
+++ b/wandb/debug.log
@@ -1 +1 @@
-run-20250420_120201-8jipcypo/logs/debug.log
\ No newline at end of file
+run-20250420_164737-uuz1f1ij/logs/debug.log
\ No newline at end of file
diff --git a/wandb/latest-run b/wandb/latest-run
index d94be8f..5a5a45c 120000
--- a/wandb/latest-run
+++ b/wandb/latest-run
@@ -1 +1 @@
-run-20250420_120201-8jipcypo
\ No newline at end of file
+run-20250420_164737-uuz1f1ij
\ No newline at end of file
diff --git a/wandb/run-20250420_120201-8jipcypo/files/output.log b/wandb/run-20250420_120201-8jipcypo/files/output.log
index 880749a..37dfdf9 100644
--- a/wandb/run-20250420_120201-8jipcypo/files/output.log
+++ b/wandb/run-20250420_120201-8jipcypo/files/output.log
@@ -79,3 +79,183 @@ Logging to runs/0420/PPO_13
 |    std                  | 1.01        |
 |    value_loss           | 35.9        |
 -----------------------------------------
+-----------------------------------------
+| rollout/                |             |
+|    ep_len_mean          | 2.99        |
+|    ep_rew_mean          | 1.92        |
+| time/                   |             |
+|    fps                  | 21          |
+|    iterations           | 5           |
+|    time_elapsed         | 8399        |
+|    total_timesteps      | 184320      |
+| train/                  |             |
+|    approx_kl            | 0.010857548 |
+|    clip_fraction        | 0.131       |
+|    clip_range           | 0.2         |
+|    entropy_loss         | -9.99       |
+|    explained_variance   | 2.86e-05    |
+|    learning_rate        | 0.0003      |
+|    loss                 | 101         |
+|    n_updates            | 20          |
+|    policy_gradient_loss | -0.00528    |
+|    std                  | 1.01        |
+|    value_loss           | 2.04e+03    |
+-----------------------------------------
+-----------------------------------------
+| rollout/                |             |
+|    ep_len_mean          | 2.96        |
+|    ep_rew_mean          | 1.92        |
+| time/                   |             |
+|    fps                  | 22          |
+|    iterations           | 6           |
+|    time_elapsed         | 10049       |
+|    total_timesteps      | 221184      |
+| train/                  |             |
+|    approx_kl            | 0.010978606 |
+|    clip_fraction        | 0.141       |
+|    clip_range           | 0.2         |
+|    entropy_loss         | -9.97       |
+|    explained_variance   | 0.00576     |
+|    learning_rate        | 0.0003      |
+|    loss                 | 0.0066      |
+|    n_updates            | 25          |
+|    policy_gradient_loss | -0.00612    |
+|    std                  | 1           |
+|    value_loss           | 54.7        |
+-----------------------------------------
+-----------------------------------------
+| rollout/                |             |
+|    ep_len_mean          | 2.99        |
+|    ep_rew_mean          | 1.86        |
+| time/                   |             |
+|    fps                  | 22          |
+|    iterations           | 7           |
+|    time_elapsed         | 11726       |
+|    total_timesteps      | 258048      |
+| train/                  |             |
+|    approx_kl            | 0.011744231 |
+|    clip_fraction        | 0.142       |
+|    clip_range           | 0.2         |
+|    entropy_loss         | -9.95       |
+|    explained_variance   | 0.00357     |
+|    learning_rate        | 0.0003      |
+|    loss                 | -0.0151     |
+|    n_updates            | 30          |
+|    policy_gradient_loss | -0.0062     |
+|    std                  | 1           |
+|    value_loss           | 74.6        |
+-----------------------------------------
+----------------------------------------
+| rollout/                |            |
+|    ep_len_mean          | 2.98       |
+|    ep_rew_mean          | 1.87       |
+| time/                   |            |
+|    fps                  | 22         |
+|    iterations           | 8          |
+|    time_elapsed         | 13345      |
+|    total_timesteps      | 294912     |
+| train/                  |            |
+|    approx_kl            | 0.01144138 |
+|    clip_fraction        | 0.141      |
+|    clip_range           | 0.2        |
+|    entropy_loss         | -9.96      |
+|    explained_variance   | -3.81e-06  |
+|    learning_rate        | 0.0003     |
+|    loss                 | 0.00169    |
+|    n_updates            | 35         |
+|    policy_gradient_loss | -0.00494   |
+|    std                  | 1.01       |
+|    value_loss           | 1.27e+06   |
+----------------------------------------
+-----------------------------------------
+| rollout/                |             |
+|    ep_len_mean          | 2.95        |
+|    ep_rew_mean          | 1.27        |
+| time/                   |             |
+|    fps                  | 22          |
+|    iterations           | 9           |
+|    time_elapsed         | 15055       |
+|    total_timesteps      | 331776      |
+| train/                  |             |
+|    approx_kl            | 0.011626828 |
+|    clip_fraction        | 0.142       |
+|    clip_range           | 0.2         |
+|    entropy_loss         | -9.96       |
+|    explained_variance   | 0.00577     |
+|    learning_rate        | 0.0003      |
+|    loss                 | 0.665       |
+|    n_updates            | 40          |
+|    policy_gradient_loss | -0.00535    |
+|    std                  | 1           |
+|    value_loss           | 55.1        |
+-----------------------------------------
+-----------------------------------------
+| rollout/                |             |
+|    ep_len_mean          | 2.96        |
+|    ep_rew_mean          | -1.78       |
+| time/                   |             |
+|    fps                  | 22          |
+|    iterations           | 10          |
+|    time_elapsed         | 16672       |
+|    total_timesteps      | 368640      |
+| train/                  |             |
+|    approx_kl            | 0.011154767 |
+|    clip_fraction        | 0.14        |
+|    clip_range           | 0.2         |
+|    entropy_loss         | -9.97       |
+|    explained_variance   | 0.00209     |
+|    learning_rate        | 0.0003      |
+|    loss                 | 296         |
+|    n_updates            | 45          |
+|    policy_gradient_loss | -0.00506    |
+|    std                  | 1.01        |
+|    value_loss           | 134         |
+-----------------------------------------
+Traceback (most recent call last):
+  File "/home/yyan-admin/yl43338/residual_grasping/train_one_step_e2e.py", line 129, in <module>
+    sys.exit(main())
+  File "/home/yyan-admin/yl43338/residual_grasping/train_one_step_e2e.py", line 116, in main
+    model.learn(
+  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn
+    return super().learn(
+  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 324, in learn
+    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
+  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 218, in collect_rollouts
+    new_obs, rewards, dones, infos = env.step(clipped_actions)
+  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 222, in step
+    return self.step_wait()
+  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py", line 137, in step_wait
+    results = [remote.recv() for remote in self.remotes]
+  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py", line 137, in <listcomp>
+    results = [remote.recv() for remote in self.remotes]
+  File "/usr/lib/python3.10/multiprocessing/connection.py", line 250, in recv
+    buf = self._recv_bytes()
+  File "/usr/lib/python3.10/multiprocessing/connection.py", line 414, in _recv_bytes
+    buf = self._recv(4)
+  File "/usr/lib/python3.10/multiprocessing/connection.py", line 379, in _recv
+    chunk = read(handle, remaining)
+KeyboardInterrupt
+Traceback (most recent call last):
+  File "/home/yyan-admin/yl43338/residual_grasping/train_one_step_e2e.py", line 129, in <module>
+    sys.exit(main())
+  File "/home/yyan-admin/yl43338/residual_grasping/train_one_step_e2e.py", line 116, in main
+    model.learn(
+  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn
+    return super().learn(
+  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 324, in learn
+    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
+  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 218, in collect_rollouts
+    new_obs, rewards, dones, infos = env.step(clipped_actions)
+  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 222, in step
+    return self.step_wait()
+  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py", line 137, in step_wait
+    results = [remote.recv() for remote in self.remotes]
+  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py", line 137, in <listcomp>
+    results = [remote.recv() for remote in self.remotes]
+  File "/usr/lib/python3.10/multiprocessing/connection.py", line 250, in recv
+    buf = self._recv_bytes()
+  File "/usr/lib/python3.10/multiprocessing/connection.py", line 414, in _recv_bytes
+    buf = self._recv(4)
+  File "/usr/lib/python3.10/multiprocessing/connection.py", line 379, in _recv
+    chunk = read(handle, remaining)
+KeyboardInterrupt
diff --git a/wandb/run-20250420_120201-8jipcypo/logs/debug-internal.log b/wandb/run-20250420_120201-8jipcypo/logs/debug-internal.log
index 93797d0..669435b 100644
--- a/wandb/run-20250420_120201-8jipcypo/logs/debug-internal.log
+++ b/wandb/run-20250420_120201-8jipcypo/logs/debug-internal.log
@@ -6,3 +6,11 @@
 {"time":"2025-04-20T12:02:01.671121657-05:00","level":"INFO","msg":"handler: started","stream_id":"8jipcypo"}
 {"time":"2025-04-20T12:02:01.82193005-05:00","level":"INFO","msg":"Starting system monitor"}
 {"time":"2025-04-20T12:02:18.192629596-05:00","level":"INFO","msg":"tensorboard: no root directory after 10 seconds, using working directory"}
+{"time":"2025-04-20T16:46:13.21465247-05:00","level":"INFO","msg":"stream: closing","id":"8jipcypo"}
+{"time":"2025-04-20T16:46:13.214671999-05:00","level":"INFO","msg":"Stopping system monitor"}
+{"time":"2025-04-20T16:46:13.214711139-05:00","level":"INFO","msg":"Stopped system monitor"}
+{"time":"2025-04-20T16:46:13.557248225-05:00","level":"INFO","msg":"fileTransfer: Close: file transfer manager closed"}
+{"time":"2025-04-20T16:46:13.640940983-05:00","level":"INFO","msg":"handler: closed","stream_id":"8jipcypo"}
+{"time":"2025-04-20T16:46:13.64100428-05:00","level":"INFO","msg":"sender: closed","stream_id":"8jipcypo"}
+{"time":"2025-04-20T16:46:13.640997219-05:00","level":"INFO","msg":"writer: Close: closed","stream_id":"8jipcypo"}
+{"time":"2025-04-20T16:46:13.64118093-05:00","level":"INFO","msg":"stream: closed","id":"8jipcypo"}
diff --git a/wandb/run-20250420_120201-8jipcypo/logs/debug.log b/wandb/run-20250420_120201-8jipcypo/logs/debug.log
index eec8216..4a31af2 100644
--- a/wandb/run-20250420_120201-8jipcypo/logs/debug.log
+++ b/wandb/run-20250420_120201-8jipcypo/logs/debug.log
@@ -22,3 +22,4 @@ config: {'policy_type': 'MlpPolicy', 'total_timesteps': 500000.0, 'env_name': 'O
 2025-04-20 12:02:01,916 INFO    MainThread:2236535 [wandb_init.py:init():1056] run started, returning control to user process
 2025-04-20 12:02:08,191 INFO    MainThread:2236535 [wandb_run.py:_tensorboard_callback():1524] tensorboard callback: runs/0420/PPO_13, True
 2025-04-20 12:02:08,193 INFO    MainThread:2236535 [wandb_run.py:_config_callback():1327] config_cb None None {'algo': 'PPO', 'policy_class': "<class 'stable_baselines3.common.policies.ActorCriticPolicy'>", 'device': 'cpu', 'verbose': 1, 'policy_kwargs': '{}', 'num_timesteps': 0, '_total_timesteps': 500000.0, '_num_timesteps_at_start': 0, 'seed': 'None', 'action_noise': 'None', 'start_time': 1745168526045631733, 'learning_rate': 0.0003, 'tensorboard_log': 'runs/0420', '_last_obs': '[[ 0.          0.          0.         ...  0.          0.\n   0.        ]\n [ 0.03061293  0.03198892  0.01950267 ...  0.          0.\n   0.        ]\n [ 0.          0.          0.         ...  0.          0.\n   0.        ]\n ...\n [-0.00492451 -0.00811863 -0.0100185  ...  0.          0.\n   0.        ]\n [ 0.          0.          0.         ...  0.          0.\n   0.        ]\n [ 0.          0.          0.         ...  0.          0.\n   0.        ]]', '_last_episode_starts': '[ True  True  True  True  True  True  True  True  True  True  True  True\n  True  True  True  True  True  True  True  True  True  True  True  True\n  True  True  True  True  True  True  True  True  True  True  True  True]', '_last_original_obs': 'None', '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 1.0, '_stats_window_size': 100, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 0, '_custom_logger': 'False', 'env': '<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7c89275129b0>', '_vec_normalize_env': 'None', 'observation_space': 'Box(-1.0, 1.0, (3000,), float64)', 'action_space': 'Box([-1.   -1.   -1.   -1.   -0.2  -0.2   0.05], [1.   1.   1.   1.   0.2  0.2  0.25], (7,), float64)', 'n_envs': 36, 'n_steps': 1024, 'gamma': 0.99, 'gae_lambda': 0.95, 'ent_coef': 0.0, 'vf_coef': 0.5, 'max_grad_norm': 0.5, 'rollout_buffer_class': "<class 'stable_baselines3.common.buffers.RolloutBuffer'>", 'rollout_buffer_kwargs': '{}', 'batch_size': 64, 'n_epochs': 5, 'clip_range': '<function get_schedule_fn.<locals>.<lambda> at 0x7c89043c8e50>', 'clip_range_vf': 'None', 'normalize_advantage': 'True', 'target_kl': 'None', 'lr_schedule': '<function get_schedule_fn.<locals>.<lambda> at 0x7c8927555f30>', 'rollout_buffer': '<stable_baselines3.common.buffers.RolloutBuffer object at 0x7c89279c8580>', 'policy': 'ActorCriticPolicy(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (pi_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (vf_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (mlp_extractor): MlpExtractor(\n    (policy_net): Sequential(\n      (0): Linear(in_features=3000, out_features=64, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n    )\n    (value_net): Sequential(\n      (0): Linear(in_features=3000, out_features=64, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64, out_features=7, bias=True)\n  (value_net): Linear(in_features=64, out_features=1, bias=True)\n)', '_logger': '<stable_baselines3.common.logger.Logger object at 0x7c8905752d70>'}
+2025-04-20 16:46:13,213 INFO    MsgRouterThr:2236535 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
diff --git a/wandb/run-20250420_120201-8jipcypo/run-8jipcypo.wandb b/wandb/run-20250420_120201-8jipcypo/run-8jipcypo.wandb
index 42e3446..9a90e40 100644
Binary files a/wandb/run-20250420_120201-8jipcypo/run-8jipcypo.wandb and b/wandb/run-20250420_120201-8jipcypo/run-8jipcypo.wandb differ
