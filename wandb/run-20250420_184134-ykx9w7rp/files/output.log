Number of CPU used for training = 36
Creating PPO model...
Using cpu device
Total number of parameters: 163471
Logging to runs/0420-4/PPO_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2        |
|    ep_rew_mean     | 1        |
| time/              |          |
|    fps             | 11       |
|    iterations      | 1        |
|    time_elapsed    | 389      |
|    total_timesteps | 4608     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.99         |
|    ep_rew_mean          | 0.99         |
| time/                   |              |
|    fps                  | 11           |
|    iterations           | 2            |
|    time_elapsed         | 787          |
|    total_timesteps      | 9216         |
| train/                  |              |
|    approx_kl            | 0.0022153547 |
|    clip_fraction        | 0.0103       |
|    clip_range           | 0.2          |
|    entropy_loss         | -9.95        |
|    explained_variance   | -0.00111     |
|    learning_rate        | 0.0003       |
|    loss                 | 75.8         |
|    n_updates            | 3            |
|    policy_gradient_loss | -0.00182     |
|    std                  | 1            |
|    value_loss           | 52.3         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2            |
|    ep_rew_mean          | 1.99         |
| time/                   |              |
|    fps                  | 11           |
|    iterations           | 3            |
|    time_elapsed         | 1188         |
|    total_timesteps      | 13824        |
| train/                  |              |
|    approx_kl            | 0.0026479336 |
|    clip_fraction        | 0.0192       |
|    clip_range           | 0.2          |
|    entropy_loss         | -9.95        |
|    explained_variance   | 0.000653     |
|    learning_rate        | 0.0003       |
|    loss                 | 0.123        |
|    n_updates            | 6            |
|    policy_gradient_loss | -0.00301     |
|    std                  | 1            |
|    value_loss           | 103          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2           |
|    ep_rew_mean          | 1.99        |
| time/                   |             |
|    fps                  | 11          |
|    iterations           | 4           |
|    time_elapsed         | 1591        |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.004488868 |
|    clip_fraction        | 0.0414      |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.94       |
|    explained_variance   | 0.00227     |
|    learning_rate        | 0.0003      |
|    loss                 | 67.5        |
|    n_updates            | 9           |
|    policy_gradient_loss | -0.00281    |
|    std                  | 0.999       |
|    value_loss           | 63.7        |
-----------------------------------------
Traceback (most recent call last):
  File "/home/yyan-admin/yl43338/residual_grasping/train_residual_one.py", line 130, in <module>
    if __name__ == "__main__":
  File "/home/yyan-admin/yl43338/residual_grasping/train_residual_one.py", line 117, in main
    while True:
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn
    return super().learn(
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 324, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 218, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 222, in step
    return self.step_wait()
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py", line 137, in step_wait
    results = [remote.recv() for remote in self.remotes]
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py", line 137, in <listcomp>
    results = [remote.recv() for remote in self.remotes]
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yyan-admin/yl43338/residual_grasping/train_residual_one.py", line 130, in <module>
    if __name__ == "__main__":
  File "/home/yyan-admin/yl43338/residual_grasping/train_residual_one.py", line 117, in main
    while True:
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn
    return super().learn(
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 324, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 218, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 222, in step
    return self.step_wait()
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py", line 137, in step_wait
    results = [remote.recv() for remote in self.remotes]
  File "/home/yyan-admin/yl43338/env/lib/python3.10/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py", line 137, in <listcomp>
    results = [remote.recv() for remote in self.remotes]
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
